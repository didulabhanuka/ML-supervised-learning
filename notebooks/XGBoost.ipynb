{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../adult.csv')  # Replace with your correct path\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 3: Split Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['income'] = le.fit_transform(df['income'])  # 0: <=50K, 1: >50K\n",
    "\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Check Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution in target (to ensure stratification worked)\n",
    "print(\"Train target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Optional: preview\n",
    "print(\"\\nSample of X_train:\")\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Visualize Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training set distribution\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Income Distribution in Training Set\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Inspect Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just preprocess the training set\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Show shape before and after\n",
    "print(\"Original shape:\", X_train.shape)\n",
    "print(\"After preprocessing:\", X_train_preprocessed.shape)\n",
    "\n",
    "# To see what features look like:\n",
    "# Convert to DataFrame if you want to inspect (for OneHotEncoded columns)\n",
    "ohe = preprocessor.named_transformers_['cat']['encoder']\n",
    "feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "all_features = np.concatenate([numeric_features, feature_names])\n",
    "\n",
    "X_df_transformed = pd.DataFrame(X_train_preprocessed.toarray() \n",
    "                                if hasattr(X_train_preprocessed, 'toarray') \n",
    "                                else X_train_preprocessed,\n",
    "                                columns=all_features)\n",
    "\n",
    "print(X_df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Data Exploration & Preprocessing Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 14))\n",
    "\n",
    "X_train[numeric_features].hist(bins=20, ax=axes[0], grid=False, edgecolor='black')\n",
    "axes[0].set_title(\"üîç Distribution of Numeric Features\", fontsize=16)\n",
    "axes[0].set_xlabel(\"Feature Value\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "corr_matrix = X_train[numeric_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=axes[1])\n",
    "axes[1].set_title(\"üìà Correlation Between Numeric Features\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 5: Define Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Basic Pipeline Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "quick_pipeline.fit(X_train, y_train)\n",
    "y_quick_pred = quick_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Quick pipeline accuracy:\", (y_quick_pred == y_test).mean())\n",
    "print(classification_report(y_test, y_quick_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå PCA to Visualize Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(\n",
    "    X_train_preprocessed.toarray() if hasattr(X_train_preprocessed, 'toarray') else X_train_preprocessed\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap='coolwarm', alpha=0.6)\n",
    "plt.title(\"PCA of Preprocessed Features\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(label=\"Income Class (0 = <=50K, 1 = >50K)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 6: Define Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [3, 6],\n",
    "    'clf__learning_rate': [0.1, 0.3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Grid Search Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best CV Score (AUC):\", grid_search.best_score_)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results[['params', 'mean_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Visualize GridSearchCV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='param_clf__n_estimators', y='mean_test_score', data=results)\n",
    "plt.title(\"Random Forest - Estimators vs Mean ROC AUC\")\n",
    "plt.ylabel(\"Mean ROC AUC\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 7: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "y_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'XGBoost (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Step 8: SHAP Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test.sample(100, random_state=42)\n",
    "X_sample_transformed = preprocessor.transform(X_sample)\n",
    "\n",
    "model = grid_search.best_estimator_.named_steps['clf']\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_sample_transformed)\n",
    "\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Optional: Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_search.best_estimator_, '../models/xgboost_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
